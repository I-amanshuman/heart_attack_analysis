{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8ebZQoEsKxnSNeQgQeGhd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/I-amanshuman/heart_attack_analysis/blob/main/heart_attack_analysis_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "uN-UzPuxR90k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JIM2ZIUbPpIs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'anshumantewary'\n",
        "os.environ['KAGGLE_KEY'] = '41b610240ed30662bb633cf567dd6025'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d rashikrahmanpritom/heart-attack-analysis-prediction-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2fiH2x8PqQY",
        "outputId": "1fe6d1eb-e5c4-49d0-b45c-91222c72ab9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zsh:1: command not found: kaggle\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/heart-attack-analysis-prediction-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irKWPnUnRnmp",
        "outputId": "25246896-5871-4e3e-ab7f-f66e0213677f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/heart-attack-analysis-prediction-dataset.zip, /content/heart-attack-analysis-prediction-dataset.zip.zip or /content/heart-attack-analysis-prediction-dataset.zip.ZIP.\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/heart.csv')"
      ],
      "metadata": {
        "id": "vhzM8xnVRyQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "81179921-4dc2-4964-e347-559c4379630a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a606d36bd645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/heart.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/heart.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5P03KTvmxfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ogsopPQqR9Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About this dataset\n",
        "\n",
        "Age : Age of the patient\n",
        "\n",
        "Sex : Sex of the patient\n",
        "\n",
        "exang: exercise induced angina (1 = yes; 0 = no)\n",
        "\n",
        "ca: number of major vessels (0-3)\n",
        "\n",
        "cp : Chest Pain type chest pain type\n",
        "\n",
        "Value 1: typical angina\n",
        "Value 2: atypical angina\n",
        "Value 3: non-anginal pain\n",
        "Value 4: asymptomatic\n",
        "\n",
        "trtbps : resting blood pressure (in mm Hg)\n",
        "\n",
        "chol : cholestoral in mg/dl fetched via BMI sensor\n",
        "\n",
        "fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
        "\n",
        "rest_ecg : resting electrocardiographic results\n",
        "\n",
        "Value 0: normal\n",
        "Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "thalach : maximum heart rate achieved\n",
        "\n",
        "target : 0= less chance of heart attack 1= more chance of heart attack\n",
        "\n"
      ],
      "metadata": {
        "id": "wUL_ScHlTuq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "iHjjPFq0SX8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "rNjAbo9jS_ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() #No null values"
      ],
      "metadata": {
        "id": "tI_WunJoUaGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "ljL0BdbQUbeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import Axes\n",
        "#Lets present this in the form of a dataframe\n",
        "\n",
        "def is_nullnumber(dataframe):\n",
        "  is_null = []\n",
        "  for i in dataframe.columns:\n",
        "    x = dataframe[i].isnull().sum()\n",
        "    is_null.append(x)\n",
        "  return is_null\n",
        "\n",
        "pd.DataFrame(is_nullnumber(df), index = df.columns, columns = [\" Total Missing Values\"] )\n",
        "\n",
        "#Clean dataframe form\n"
      ],
      "metadata": {
        "id": "viC96T_GWJX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets visualize the missing values\n",
        "\n",
        "import missingno\n",
        "missingno.bar(df, color = 'black')"
      ],
      "metadata": {
        "id": "nWgr0I14XBcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets examine the unique values\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "g18aSomzZYAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unq_values(dataframe):\n",
        "  unq = []\n",
        "  for i in dataframe.columns:\n",
        "    x = dataframe[i].value_counts().count()\n",
        "    unq.append(x)\n",
        "  return unq\n",
        "\n",
        "unq_df = pd.DataFrame(unq_values(df), index = df.columns, columns = [\"Total unique values\" ])\n",
        "\n",
        "unq_df"
      ],
      "metadata": {
        "id": "46CRDIIKZ2Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets say that all the variables which have a a count of total unique values <= 5, are categorical\n",
        "#Or we want them to be categorical in nature for better understanding\n",
        "#Lets separate the variables in two lists, numeric and categorical\n",
        "\n",
        "categoric_var = unq_df[ unq_df['Total unique values'] <= 5 ]\n",
        "print(\"Categoric Variables\",categoric_var.index)\n",
        "\n",
        "numeric_var = unq_df[ unq_df['Total unique values'] > 5  ]\n",
        "print( \"Numeric Variables\",  numeric_var.index ) "
      ],
      "metadata": {
        "id": "R6ZXQSOQa-2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[numeric_var.index].describe()"
      ],
      "metadata": {
        "id": "fMGzlvBCddEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets check the distribution of the age variable, since we are seeing that 50% of the age lies <= 55, assuming the distribution is linear"
      ],
      "metadata": {
        "id": "47A4Phq6ZunO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['age'], hist_kws = dict(linewidth = 1, edgecolor = 'r')) #Avg age is 54~55"
      ],
      "metadata": {
        "id": "S3AFsshfbqBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['trtbps'], bins = 20, hist_kws = dict(linewidth = 1, edgecolor = 'r')) #Avg blood pressure us ~ 120 - 130"
      ],
      "metadata": {
        "id": "24sqtElxbt9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we want the data to be normally distributed, coz they are the most suitable for ML algorithms"
      ],
      "metadata": {
        "id": "MJOGSoRgcpx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['chol'], hist = False) #Slight right skew"
      ],
      "metadata": {
        "id": "FzHMI45wc5-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x,y = plt.subplots(figsize = (8,6))\n",
        "sns.distplot(df['thalachh'], hist = False, ax = y)\n",
        "y.axvline(df['thalachh'].mean(), color = 'r', ls = '--')"
      ],
      "metadata": {
        "id": "0uf6Nj7TdPNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = plt.subplots(figsize = (8,6))\n",
        "sns.distplot(df['oldpeak'], hist_kws = dict(linewidth = 1, edgecolor = 'k'), ax = y)\n",
        "y.axvline(df['oldpeak'].mean(), color = 'r', ls = '--')\n",
        "\n",
        "#data is extremely right skewed"
      ],
      "metadata": {
        "id": "4HZvboNDdrXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analytics (Univariate analysis)"
      ],
      "metadata": {
        "id": "kJOyWC7NfuhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_font = { \"family\":\"arial\", \"color\":\"red\", \"weight\":\"bold\", \"size\":15   }\n",
        "axis_font = {   \"family\":\"arial\", \"color\":\"blue\", \"weight\":\"bold\", \"size\":10    }\n",
        "\n",
        "numeric_axis_name = [\"Age of Patient\", \"Resting Blood Pressure\", \"Cholestrol\", \"Maximum heart rate achieved\", \"ST Depression\"]\n",
        "list(zip(numeric_var.index, numeric_axis_name)) #Zipping values together to run in for loop\n",
        "\n",
        "for i,z in list(zip(numeric_var.index, numeric_axis_name)): #i will store index values, whereas, z will store modified values\n",
        "  plt.figure(figsize = (8,6), dpi = 80)\n",
        "  sns.distplot(df[i], hist_kws = dict(linewidth = 1, edgecolor = 'k'))\n",
        "\n",
        "  plt.title(i, fontdict = title_font)\n",
        "  plt.xlabel(z, fontdict = axis_font) #We customized the x-label\n",
        "  plt.ylabel(\"Density\", fontdict = axis_font)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "LbRtlPqDf0Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis\n",
        "1.   Age: There is a decrease in patients (against the trend) b/w ages  47-50,for reasons not yet known and no outliers\n",
        "2.   Resting blood pressure: Values between 110 - 140, with some outliers\n",
        "3. Cholestrol: Some outliers\n",
        "4. Heart rate: Values before 80 are outliers\n",
        "5. ST depression: Within this variable, the values range from 0-1.5 and after 2.5, we can say that they are outliers\n",
        "\n"
      ],
      "metadata": {
        "id": "PodNYPCqmm-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using categorical variables"
      ],
      "metadata": {
        "id": "Sr9rololoMeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categoric_var"
      ],
      "metadata": {
        "id": "Wj5qRyt1gFS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(df['cp'].value_counts())"
      ],
      "metadata": {
        "id": "FstUG3u_r-4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(df['cp'].value_counts().index)"
      ],
      "metadata": {
        "id": "3-C0hGiasKw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categoric_axis_name = [\"Gender\", \"Chest Pain type\", \"Fasting Blood Sugar\", \"Resting ECG results\", \"Exercise induce angina\", \"Slope of ST Segment\", \"Number of major vessels\", \"Thal\", \"Target\"   ]"
      ],
      "metadata": {
        "id": "Kw16g4QWoMJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(categoric_var.index, categoric_axis_name))"
      ],
      "metadata": {
        "id": "dfbaA5vRoFyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_font = { \"family\":\"arial\", \"color\":\"red\", \"weight\":\"bold\", \"size\":15   }\n",
        "axis_font = {   \"family\":\"arial\", \"color\":\"blue\", \"weight\":\"bold\", \"size\":10    }\n",
        "\n",
        "for i,z in list(zip(categoric_var.index, categoric_axis_name)):\n",
        "  fig, ax = plt.subplots(figsize = (8,6))\n",
        "  \n",
        "  observation_values = list(df[i].value_counts().index)\n",
        "  total_number_obs = list(df[i].value_counts())\n",
        "\n",
        "  ax.pie(total_number_obs, labels = observation_values, autopct = '%1.1f%%', startangle = 110, labeldistance = 1.1)\n",
        "  ax.axis(\"equal\")\n",
        "\n",
        "  plt.title((i+ \"(\" + z + \")\"), fontdict = title_font)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "i7bsoEruoD2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Considering the dataset and explanation, we have found that there is missing data in thal column, which should have 3 results but the data shows we have 4\n",
        "df[df['thall']==0]\n"
      ],
      "metadata": {
        "id": "uknBiCwPml3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['thall'] = df[\"thall\" ].replace(0, np.nan)"
      ],
      "metadata": {
        "id": "w_vJptEEW2Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[[48, 281], :]"
      ],
      "metadata": {
        "id": "I8wv6XduXVZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets check if this reflects on the for loop we made to identify missing values\n",
        "def is_nullnumber(dataframe):\n",
        "  is_null = []\n",
        "  for i in dataframe.columns:\n",
        "    x = dataframe[i].isnull().sum()\n",
        "    is_null.append(x)\n",
        "  return is_null\n",
        "\n",
        "pd.DataFrame(is_nullnumber(df), index = df.columns, columns = [\" Total Missing Values\"] )"
      ],
      "metadata": {
        "id": "xdfY5-PVXePH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets fill the nan values with the most occured value\n",
        "#As per the analys above, \"thall\" has most occurence of 2, approx 55%\n",
        "#Replacing the same in the table\n",
        "\n",
        "df['thall'].fillna(2, inplace = True)\n",
        "df.loc[[48, 281], :]"
      ],
      "metadata": {
        "id": "7p1ADBo_Xtzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "o5vqPm-mYdwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#thall has all values in float type, lets convert them to integer so as to get results in visualizing them\n",
        "df [ 'thall']=pd.to_numeric(df['thall'], downcast = 'integer')\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "id": "ieCgyyH1Yvan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['thall'].value_counts()\n",
        "\n",
        "#Job done"
      ],
      "metadata": {
        "id": "SGGndu1XZOj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analytics (Bivariate analysis)"
      ],
      "metadata": {
        "id": "VMdKpQvfZ7Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Currently our numeric variable does not have the target variable (output)\n",
        "#We need the target variable to compare the numeric types with the target variable\n",
        "#Lets create the target variable as a dataframe and then append it to the numeric_variable"
      ],
      "metadata": {
        "id": "y3VCP_mjeLqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_target = pd.concat([numeric_var, (pd.DataFrame([df['output'].value_counts().count()], index=[\"output\"], columns = ['Total unique values']))])"
      ],
      "metadata": {
        "id": "YIh02DvFiT06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets explore the relationship of each column with the \"target\" column\\\n",
        "#With Numeric variables\n",
        "\n",
        "\n",
        "title_font = { \"family\":\"arial\", \"color\":\"red\", \"weight\":\"bold\", \"size\":15   }\n",
        "axis_font = {   \"family\":\"arial\", \"color\":\"blue\", \"weight\":\"bold\", \"size\":10    }\n",
        "\n",
        "numeric_axis_name = [\"Age of Patient\", \"Resting Blood Pressure\", \"Cholestrol\", \"Maximum heart rate achieved\", \"ST Depression\", \"Target output\"]\n",
        "list(zip(num_target.index, numeric_axis_name)) #Zipping values together to run in for loop\n",
        "\n",
        "for i,z in list(zip(num_target.index, numeric_axis_name)): #i will store index values, whereas, z will store modified values\n",
        "  \n",
        "  graph = sns.FacetGrid(df[num_target.index], hue = \"output\", height=5, aspect=1,  xlim = ((df[i].min()-10), (df[i].max()+10))) #We are extending the x-axis by +- 10 on both sides based on the min and max value\n",
        "  graph.map (sns.kdeplot, i, shade = True)\n",
        "  graph.add_legend()\n",
        "  \n",
        "  plt.title(i, fontdict = title_font)\n",
        "  plt.xlabel(z, fontdict = axis_font) #We customized the x-label\n",
        "  plt.ylabel(\"Density\", fontdict = axis_font)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "k535647YZYAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df[num_target.index].corr())"
      ],
      "metadata": {
        "id": "Ame5ePabamyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[num_target.index].corr().iloc[:, [-1]] #No such correlation #I want the output in the form of a dataframe, hence the square brackets"
      ],
      "metadata": {
        "id": "j10eLkBSsfiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CynuXeWPstgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorical variables - target variable analysis with count plot"
      ],
      "metadata": {
        "id": "i_lLLQUvB8yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_font = { \"family\":\"arial\", \"color\":\"red\", \"weight\":\"bold\", \"size\":15   }\n",
        "axis_font = {   \"family\":\"arial\", \"color\":\"blue\", \"weight\":\"bold\", \"size\":10    }\n",
        "\n",
        "list(zip(categoric_var.index, categoric_axis_name)) #Zipping values together to run in for loop\n",
        "\n",
        "for i,z in list(zip(categoric_var.index, categoric_axis_name)): #i will store index values, whereas, z will store modified values\n",
        "  plt.figure(figsize = (8,5))\n",
        "  graph = sns.countplot(i, data = df[categoric_var.index], hue = \"output\") \n",
        "  plt.title(i + \" - Target\", fontdict = title_font)\n",
        "  plt.xlabel(z, fontdict = axis_font) #We customized the x-label\n",
        "  plt.ylabel(\"Target\", fontdict = axis_font)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "07FTRXGqUSUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysis of the output\n",
        "1. On patients with sex = 0, i.e woman, risk of heart attack is half of those of men (1)\n",
        "2. CP is the type of pain: probability of heart attack is almost none for 0 but 3x times higher on other cases\n",
        "3. Fasting blood sugar, patients with fasting blood sugar higher than 120 are more susceptible to heart attacks\n",
        "4. Rest ECG of value 1: Probability of having a HEART attack is 2x whereas is different in other cases\n",
        "5. exang: Exercise induced angina: PAIN DUE TO EXERCISE, does not affect heart attack, as showed by graph with value 1\n",
        "6. Slope: Patients with slope variable of 2 are 3 times more riskier of having a heart attack\n",
        "7. CAA: Patients with a CAA value of 0 have a highers chance of having a heart attack than the other patients\n",
        "8. thall: For thall: 2, we find that the value that draws our attention is the value 2, we can say that for other values that the incidence is reversed\n",
        "9. Patients of having a risk of heart attack are more.\n"
      ],
      "metadata": {
        "id": "4C1M-FhjFQJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[categoric_var.index].corr().iloc[:, [-1]] #No such correlation #I want the output in the form of a dataframe, hence the square brackets"
      ],
      "metadata": {
        "id": "p1pjC7h6Eiw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df[categoric_var.index].corr())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-DS1C966FP8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Understanding relationship between numerical variables using pair plot"
      ],
      "metadata": {
        "id": "QXZMxwI7JVC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_var.index"
      ],
      "metadata": {
        "id": "wk14rJWXIa6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[numeric_var.index].head()"
      ],
      "metadata": {
        "id": "uB5plSOZL-3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "graph = sns.pairplot(df[numeric_var.index], diag_kind = \"kde\")\n",
        "graph.map_lower(sns.kdeplot, levels = 4, color = \".2\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "woaw-4saMC-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature scaling with RobustScaler Method\n",
        "\n",
        "We will now compare cross-comparison, i.e numerical with categorical mixed (and that is precisely why we need to scale the data, to nullify the difference in values)\n",
        "\n",
        "Normalization\n",
        "\n",
        "Standardization\n",
        "\n",
        "Robust Scaler gives better results in data with outliers, because it removes the outliers and places them in the 1st and 3rd quartile of the data\n",
        "\n"
      ],
      "metadata": {
        "id": "zB_kwI0wjDoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "robust_scaler = RobustScaler()"
      ],
      "metadata": {
        "id": "3Zy3yNFeM297"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_data = robust_scaler.fit_transform(df[numeric_var.index])"
      ],
      "metadata": {
        "id": "Bqj6Yl2nk4fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_data"
      ],
      "metadata": {
        "id": "QDy4A6GPlTnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled = pd.DataFrame(scaled_data, columns = numeric_var.index )"
      ],
      "metadata": {
        "id": "2-QbtLt1lWhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled"
      ],
      "metadata": {
        "id": "PFCEDxR_ll1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.concat([df_scaled, df.iloc[:,-1 ]], axis = 1  )"
      ],
      "metadata": {
        "id": "qgDsvYxtlncl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new"
      ],
      "metadata": {
        "id": "4ydFP1ArmU3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Melt function is used to create a pivot table here"
      ],
      "metadata": {
        "id": "8snikfIlnTBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "melted_data = pd.melt(df_new, id_vars = \"output\", var_name = \"variables\", value_name = \"value\"   ) "
      ],
      "metadata": {
        "id": "mSRQcFqtmdhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melted_data"
      ],
      "metadata": {
        "id": "VaNX9PTWnFsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize= (10,8))\n",
        "sns.swarmplot(x = \"variables\", y = \"value\", hue = \"output\", data = melted_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "owj8unx6nHb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Analyse all the variables together, except the target using swarmplot (Numerical + Categorical)"
      ],
      "metadata": {
        "id": "qAJIOH03nu3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "axis_font = {   \"family\":\"arial\", \"color\":\"black\", \"weight\":\"bold\", \"size\":10    }\n",
        "\n",
        "for i in df[categoric_var.index]:\n",
        "  df_new = pd.concat([df_scaled, df.loc[:,i ]], axis = 1  )\n",
        "  melted_data = pd.melt(df_new, id_vars = i, var_name = \"variables\", value_name = \"value\"   ) \n",
        "  plt.figure(figsize= (10,8))\n",
        "  sns.swarmplot(x = \"variables\", y = \"value\", hue = i, data = melted_data)\n",
        "  plt.xlabel('Variables', fontdict = axis_font)\n",
        "  plt.ylabel(\"Value\", fontdict = axis_font)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "LyC3tI7ArioO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of the variables using box-plot"
      ],
      "metadata": {
        "id": "6FTdqFtUwUBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "axis_font = {   \"family\":\"arial\", \"color\":\"black\", \"weight\":\"bold\", \"size\":10    }\n",
        "\n",
        "for i in df[categoric_var.index]:\n",
        "  df_new = pd.concat([df_scaled, df.loc[:,i ]], axis = 1  )\n",
        "  melted_data = pd.melt(df_new, id_vars = i, var_name = \"variables\", value_name = \"value\"   ) \n",
        "  plt.figure(figsize= (10,8))\n",
        "  sns.boxplot(x = \"variables\", y = \"value\", hue = i, data = melted_data)\n",
        "  plt.xlabel('Variables', fontdict = axis_font)\n",
        "  plt.ylabel(\"Value\", fontdict = axis_font)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "swb69vVFsnqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3pTjE44fcaiH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}